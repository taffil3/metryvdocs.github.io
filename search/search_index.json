{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to MetryV Docs Overview This documentation targets developers in metryv project MetryV is the product name, and the meaning is that metry stands for metrics and v for vitals. We\u2019re focused on solving problems regarding the most vital metrics for better User Experience. By giving the best experience to your users, you get to keep them longer on the site, as a result of which you get more engagement from them, more scrolling, better conversions, and all this meaning more profit. What does Good User Experience mean? Google has defined three core aspects of user experience as vital for web pages. You may know them as Core Web Vitals, which measure loading time of the page, interactivity and also visual stability. Let\u2019s focus for a second on loading time. There is a research done by the All in one SEO tool team, where they found that 40% of users abandon a web page if it takes more than 3 seconds to load. That means that if you have a page that loads very slow, you\u2019re probably losing 40% of your potential clients. It affects the users psychologically by waiting too long that maybe your website is not worth it, they will get bored and just leave the site, even if you have the best SEO campaigns in the world. Another thing that needs to be considered too is that in the past years Google has also started taking into calculation these metrics in their ranking algorithm as well. And that percentage will get higher with time. Now we offer a tool for all of these metrics. With MetryV you can add a site easily by just adding the page url. Monitor web vitals with daily and monthly graphs. Have notifications for metric alerts for Email, Slack or Discord, also you can choose which types of notifications you want. Other cool features like Server Uptime monitoring, w3 validator tool scans and Screenshot Analysis, which takes screenshots hourly of your website to check if there are any significant differences that you need to be worried about.","title":"Overview"},{"location":"#welcome-to-metryv-docs","text":"","title":"Welcome to MetryV Docs"},{"location":"#overview","text":"This documentation targets developers in metryv project MetryV is the product name, and the meaning is that metry stands for metrics and v for vitals. We\u2019re focused on solving problems regarding the most vital metrics for better User Experience. By giving the best experience to your users, you get to keep them longer on the site, as a result of which you get more engagement from them, more scrolling, better conversions, and all this meaning more profit. What does Good User Experience mean? Google has defined three core aspects of user experience as vital for web pages. You may know them as Core Web Vitals, which measure loading time of the page, interactivity and also visual stability. Let\u2019s focus for a second on loading time. There is a research done by the All in one SEO tool team, where they found that 40% of users abandon a web page if it takes more than 3 seconds to load. That means that if you have a page that loads very slow, you\u2019re probably losing 40% of your potential clients. It affects the users psychologically by waiting too long that maybe your website is not worth it, they will get bored and just leave the site, even if you have the best SEO campaigns in the world. Another thing that needs to be considered too is that in the past years Google has also started taking into calculation these metrics in their ranking algorithm as well. And that percentage will get higher with time. Now we offer a tool for all of these metrics. With MetryV you can add a site easily by just adding the page url. Monitor web vitals with daily and monthly graphs. Have notifications for metric alerts for Email, Slack or Discord, also you can choose which types of notifications you want. Other cool features like Server Uptime monitoring, w3 validator tool scans and Screenshot Analysis, which takes screenshots hourly of your website to check if there are any significant differences that you need to be worried about.","title":"Overview"},{"location":"Docker/","text":"Docker Optionally you can run metryv from docker. First of all install docker on your machine through installation guide on docker documentation. After that you can start pulling metryv images on docker hub Docker hub Docker hub account Username Password Metryv Starlabs123321@ There are eight repositories containing images on dockerhub, commands witten on brackets [ ], are optional Api docker pull [OPTIONS] metryv/api[:TAG|@DIGEST] Psi docker pull [OPTIONS] metryv/psi[:TAG|@DIGEST] Ping docker pull [OPTIONS] metryv/ping[:TAG|@DIGEST] Chat Server docker pull [OPTIONS] metryv/chatbot[:TAG|@DIGEST] Psi-Crons docker pull [OPTIONS] metryv/psi-crons[:TAG|@DIGEST] Api-Crons docker pull [OPTIONS] metryv/api-crons[:TAG|@DIGEST] Suggestions docker pull [OPTIONS] metryv/suggestions[:TAG|@DIGEST] Dashboard docker pull [OPTIONS] metryv/dashboard[:TAG|@DIGEST] Docker Compose Docker compose is used to build and run Backend part contianing api,psi,chat_server and ping Crons server contianing api-crons and psi-crons. Make sure to set the crons variable on .env to \"crons\" Frontend with dashboard and suggestions Docker compose files are in each repo Run this command to build the Docker images: docker-compose up -d --build The data persists since we're using Docker volume (named volume) which is the preferred mechanism for persisting data generated and used by Docker containers, you can the volume created by running this docker command on your machine: docker volume ls To tear down our containers, use docker-compose down: docker-compose down To run the containers again use: docker-compose up -d After you run docker-compose, you can check the project in localhost on your machine. const targetElements = document.getElementsByClassName(\"password\"); for(const element of targetElements){ element.style.filter = \"blur(4px)\"; element.addEventListener(\"click\", (el) => { el.target.style.filter = \"blur(0px)\"; }) }","title":"Docker"},{"location":"Docker/#docker","text":"Optionally you can run metryv from docker. First of all install docker on your machine through installation guide on docker documentation. After that you can start pulling metryv images on docker hub","title":"Docker"},{"location":"Docker/#docker-hub","text":"Docker hub account Username Password Metryv Starlabs123321@ There are eight repositories containing images on dockerhub, commands witten on brackets [ ], are optional Api docker pull [OPTIONS] metryv/api[:TAG|@DIGEST] Psi docker pull [OPTIONS] metryv/psi[:TAG|@DIGEST] Ping docker pull [OPTIONS] metryv/ping[:TAG|@DIGEST] Chat Server docker pull [OPTIONS] metryv/chatbot[:TAG|@DIGEST] Psi-Crons docker pull [OPTIONS] metryv/psi-crons[:TAG|@DIGEST] Api-Crons docker pull [OPTIONS] metryv/api-crons[:TAG|@DIGEST] Suggestions docker pull [OPTIONS] metryv/suggestions[:TAG|@DIGEST] Dashboard docker pull [OPTIONS] metryv/dashboard[:TAG|@DIGEST]","title":"Docker hub"},{"location":"Docker/#docker-compose","text":"Docker compose is used to build and run Backend part contianing api,psi,chat_server and ping Crons server contianing api-crons and psi-crons. Make sure to set the crons variable on .env to \"crons\" Frontend with dashboard and suggestions Docker compose files are in each repo Run this command to build the Docker images: docker-compose up -d --build The data persists since we're using Docker volume (named volume) which is the preferred mechanism for persisting data generated and used by Docker containers, you can the volume created by running this docker command on your machine: docker volume ls To tear down our containers, use docker-compose down: docker-compose down To run the containers again use: docker-compose up -d After you run docker-compose, you can check the project in localhost on your machine. const targetElements = document.getElementsByClassName(\"password\"); for(const element of targetElements){ element.style.filter = \"blur(4px)\"; element.addEventListener(\"click\", (el) => { el.target.style.filter = \"blur(0px)\"; }) }","title":"Docker Compose"},{"location":"Google%20Developer%20Console/","text":"Google Developer Console Page Speed Insights (PSI) PageSpeed Insights (PSI) reports on the user experience of a page on both mobile and desktop devices, and provides suggestions on how that page may be improved. PSI provides both lab and field data about a page. Lab data is useful for debugging issues, as it is collected in a controlled environment. Field data is useful for capturing true, real-world user experience - but has a more limited set of metrics. Real-user experience data Real-user experience data in PSI is powered by the Chrome User Experience Report (CrUX) dataset. PSI reports real users' First Contentful Paint (FCP) , First Input Delay (FID) , Largest Contentful Paint (LCP) , and Cumulative Layout Shift (CLS) experiences over the previous 28-day collection period. In order to show user experience data for a given page, there must be sufficient data for it to be included in the CrUX dataset. A page might not have sufficient data if it has been recently published or has too few samples from real users, in which case PSI will be unable to show any real-user experience data. Lab diagnostics PSI uses Lighthouse to analyze the given URL in a simulated environment for the Performance, Accessibility, Best Practices, and SEO categories. Score At the top of the section are scores for each category, determined by running Lighthouse to collect and analyze diagnostic information about the page. A score of 90 or above is considered good. 50 to 89 is a score that needs improvement, and below 50 is considered poor. Example We are using an npm package psi gto get these data When using this module for a production-level build process, registering for an API key from the Google Developer Console is recommended. const psi = require('psi'); Get the PageSpeed Insights report for Mobile or Desktop Devices; dataMobile or dataDesktop. let dataMobile|dataDesktop = await psi(url, { key: key, strategy: \"mobile|desktop\", }); Get the PageSpeed Insights report from lighthouse let overallScore = dataMobile|dataDesktop.data.lighthouseResult.categories.performance.score; let lighthouse = dataMobile|dataDesktop.data.lighthouseResult; let lighthouseMetrics = { fcp: lighthouse.audits[\"first-contentful-paint\"].displayValue, tti: lighthouse.audits[\"interactive\"].displayValue, si: lighthouse.audits[\"speed-index\"].displayValue, tbt: lighthouse.audits[\"total-blocking-time\"].displayValue, lcp: lighthouse.audits[\"largest-contentful-paint\"].displayValue, cls: lighthouse.audits[\"cumulative-layout-shift\"].displayValue, }; Get the PageSpeed Insights report from chrome user experience report let cruxFieldData = dataMobile.data.loadingExperience; let cruxMetrics = { fcp: { score: cruxFieldData.metrics.FIRST_CONTENTFUL_PAINT_MS ? cruxFieldData.metrics.FIRST_CONTENTFUL_PAINT_MS .percentile / 1000 : null, category: cruxFieldData.metrics.FIRST_CONTENTFUL_PAINT_MS ? cruxFieldData.metrics.FIRST_CONTENTFUL_PAINT_MS.category : null, distributions: cruxFieldData.metrics.FIRST_CONTENTFUL_PAINT_MS ? cruxFieldData.metrics.FIRST_CONTENTFUL_PAINT_MS .distributions : null, }, fid: { score: cruxFieldData.metrics.FIRST_INPUT_DELAY_MS ? cruxFieldData.metrics.FIRST_INPUT_DELAY_MS.percentile : null, category: cruxFieldData.metrics.FIRST_INPUT_DELAY_MS ? cruxFieldData.metrics.FIRST_INPUT_DELAY_MS.category : null, distributions: cruxFieldData.metrics.FIRST_INPUT_DELAY_MS ? cruxFieldData.metrics.FIRST_INPUT_DELAY_MS.distributions : null, }, lcp: { score: cruxFieldData.metrics.LARGEST_CONTENTFUL_PAINT_MS ? cruxFieldData.metrics.LARGEST_CONTENTFUL_PAINT_MS .percentile / 1000 : null, category: cruxFieldData.metrics.LARGEST_CONTENTFUL_PAINT_MS ? cruxFieldData.metrics.LARGEST_CONTENTFUL_PAINT_MS.category : null, distributions: cruxFieldData.metrics.LARGEST_CONTENTFUL_PAINT_MS ? cruxFieldData.metrics.LARGEST_CONTENTFUL_PAINT_MS .distributions : null, }, cls: { score: cruxFieldData.metrics.CUMULATIVE_LAYOUT_SHIFT_SCORE ? cruxFieldData.metrics.CUMULATIVE_LAYOUT_SHIFT_SCORE .percentile / 100 : null, category: cruxFieldData.metrics.CUMULATIVE_LAYOUT_SHIFT_SCORE ? cruxFieldData.metrics.CUMULATIVE_LAYOUT_SHIFT_SCORE .category : null, distributions: cruxFieldData.metrics .CUMULATIVE_LAYOUT_SHIFT_SCORE ? cruxFieldData.metrics.CUMULATIVE_LAYOUT_SHIFT_SCORE .distributions : null, }, overall_category: cruxFieldData ? cruxFieldData.overall_category : null, }; Google Analytics Data API The Google Analytics Data API v1 gives you access to Google Analytics 4 (GA4) report data. Google Analytics 4 helps you understand how people use your web, iOS, or Android app. With the Google Analytics Data API v1, you can create reports to answer questions like: How many daily active users has my Android app had in the last week? How many page views has each of the top 10 page URLs for my site received in the last 28 days? How many active users per country has my iOS app had in the last 30 minutes? First of all we have to enable the api by going to Google Cloud Console and choosing the project, and by going on api & service we choose libraries on the dropdown menu, and search for Google Analytics Data API we want to enable this api, than reading the docs. Read the Api quick start from google docs, to get started with this client library. To call this report we use @google-analytics/data a client library for node js, and we call runReport method to return a customized report of our google analytics event data. // propertyId = 'YOUR-GA4-PROPERTY-ID'; // Imports the Google Analytics Data API client library. const {BetaAnalyticsDataClient} = require('@google-analytics/data'); const credentials = require(\"credentials.json\"); // Using a default constructor instructs the client to use the credentials // specified in GOOGLE_APPLICATION_CREDENTIALS environment variable. // We get the credentials by enabling the api in api quick start const analyticsDataClient = new BetaAnalyticsDataClient({ credentials }); // Runs a simple report. // propertyId and dimension are fetched from client side const [response] = await analyticsDataClient.runReport({ property: `properties/${propertyId}`, dateRanges: [ { startDate: \"2020-03-31\", endDate: \"today\", }, ], dimensions: [{ name: `${dimension}` }], metrics: [ { name: \"activeUsers\" }, { name: \"newUsers\" }, { name: \"totalUsers\" }, ], }); console.log('Report result:'); response.rows.forEach(row => { console.log(row.dimensionValues[0], row.metricValues[0]); }); } The following dimensions can be requested in reports for any property. Specify the \"API Name\" in a Dimension's name field for a column of the dimension in the report response. The following metrics can be requested in reports for any property. Specify the \"API Name\" in a Metric's name field for a column of the metric in the report response. To fetch the propertyId: - First go to your Google Analytics Dashboard - Go to Admin Section on the bottom left corner of your Google Analytics dashboard. On this page you'll see on the center the Property Settings, go to that section and copy your PROPERTY ID to our input above. - If you don't have a Google Analytics 4 property created for your site go on the Admin Page and follow up with the Setup Assistant to create this property.","title":"Google Developer Console"},{"location":"Google%20Developer%20Console/#google-developer-console","text":"","title":"Google Developer Console"},{"location":"Google%20Developer%20Console/#page-speed-insights-psi","text":"PageSpeed Insights (PSI) reports on the user experience of a page on both mobile and desktop devices, and provides suggestions on how that page may be improved. PSI provides both lab and field data about a page. Lab data is useful for debugging issues, as it is collected in a controlled environment. Field data is useful for capturing true, real-world user experience - but has a more limited set of metrics.","title":"Page Speed Insights (PSI)"},{"location":"Google%20Developer%20Console/#real-user-experience-data","text":"Real-user experience data in PSI is powered by the Chrome User Experience Report (CrUX) dataset. PSI reports real users' First Contentful Paint (FCP) , First Input Delay (FID) , Largest Contentful Paint (LCP) , and Cumulative Layout Shift (CLS) experiences over the previous 28-day collection period. In order to show user experience data for a given page, there must be sufficient data for it to be included in the CrUX dataset. A page might not have sufficient data if it has been recently published or has too few samples from real users, in which case PSI will be unable to show any real-user experience data.","title":"Real-user experience data"},{"location":"Google%20Developer%20Console/#lab-diagnostics","text":"PSI uses Lighthouse to analyze the given URL in a simulated environment for the Performance, Accessibility, Best Practices, and SEO categories.","title":"Lab diagnostics"},{"location":"Google%20Developer%20Console/#score","text":"At the top of the section are scores for each category, determined by running Lighthouse to collect and analyze diagnostic information about the page. A score of 90 or above is considered good. 50 to 89 is a score that needs improvement, and below 50 is considered poor.","title":"Score"},{"location":"Google%20Developer%20Console/#example","text":"We are using an npm package psi gto get these data When using this module for a production-level build process, registering for an API key from the Google Developer Console is recommended. const psi = require('psi'); Get the PageSpeed Insights report for Mobile or Desktop Devices; dataMobile or dataDesktop. let dataMobile|dataDesktop = await psi(url, { key: key, strategy: \"mobile|desktop\", }); Get the PageSpeed Insights report from lighthouse let overallScore = dataMobile|dataDesktop.data.lighthouseResult.categories.performance.score; let lighthouse = dataMobile|dataDesktop.data.lighthouseResult; let lighthouseMetrics = { fcp: lighthouse.audits[\"first-contentful-paint\"].displayValue, tti: lighthouse.audits[\"interactive\"].displayValue, si: lighthouse.audits[\"speed-index\"].displayValue, tbt: lighthouse.audits[\"total-blocking-time\"].displayValue, lcp: lighthouse.audits[\"largest-contentful-paint\"].displayValue, cls: lighthouse.audits[\"cumulative-layout-shift\"].displayValue, }; Get the PageSpeed Insights report from chrome user experience report let cruxFieldData = dataMobile.data.loadingExperience; let cruxMetrics = { fcp: { score: cruxFieldData.metrics.FIRST_CONTENTFUL_PAINT_MS ? cruxFieldData.metrics.FIRST_CONTENTFUL_PAINT_MS .percentile / 1000 : null, category: cruxFieldData.metrics.FIRST_CONTENTFUL_PAINT_MS ? cruxFieldData.metrics.FIRST_CONTENTFUL_PAINT_MS.category : null, distributions: cruxFieldData.metrics.FIRST_CONTENTFUL_PAINT_MS ? cruxFieldData.metrics.FIRST_CONTENTFUL_PAINT_MS .distributions : null, }, fid: { score: cruxFieldData.metrics.FIRST_INPUT_DELAY_MS ? cruxFieldData.metrics.FIRST_INPUT_DELAY_MS.percentile : null, category: cruxFieldData.metrics.FIRST_INPUT_DELAY_MS ? cruxFieldData.metrics.FIRST_INPUT_DELAY_MS.category : null, distributions: cruxFieldData.metrics.FIRST_INPUT_DELAY_MS ? cruxFieldData.metrics.FIRST_INPUT_DELAY_MS.distributions : null, }, lcp: { score: cruxFieldData.metrics.LARGEST_CONTENTFUL_PAINT_MS ? cruxFieldData.metrics.LARGEST_CONTENTFUL_PAINT_MS .percentile / 1000 : null, category: cruxFieldData.metrics.LARGEST_CONTENTFUL_PAINT_MS ? cruxFieldData.metrics.LARGEST_CONTENTFUL_PAINT_MS.category : null, distributions: cruxFieldData.metrics.LARGEST_CONTENTFUL_PAINT_MS ? cruxFieldData.metrics.LARGEST_CONTENTFUL_PAINT_MS .distributions : null, }, cls: { score: cruxFieldData.metrics.CUMULATIVE_LAYOUT_SHIFT_SCORE ? cruxFieldData.metrics.CUMULATIVE_LAYOUT_SHIFT_SCORE .percentile / 100 : null, category: cruxFieldData.metrics.CUMULATIVE_LAYOUT_SHIFT_SCORE ? cruxFieldData.metrics.CUMULATIVE_LAYOUT_SHIFT_SCORE .category : null, distributions: cruxFieldData.metrics .CUMULATIVE_LAYOUT_SHIFT_SCORE ? cruxFieldData.metrics.CUMULATIVE_LAYOUT_SHIFT_SCORE .distributions : null, }, overall_category: cruxFieldData ? cruxFieldData.overall_category : null, };","title":"Example"},{"location":"Google%20Developer%20Console/#google-analytics-data-api","text":"The Google Analytics Data API v1 gives you access to Google Analytics 4 (GA4) report data. Google Analytics 4 helps you understand how people use your web, iOS, or Android app. With the Google Analytics Data API v1, you can create reports to answer questions like: How many daily active users has my Android app had in the last week? How many page views has each of the top 10 page URLs for my site received in the last 28 days? How many active users per country has my iOS app had in the last 30 minutes? First of all we have to enable the api by going to Google Cloud Console and choosing the project, and by going on api & service we choose libraries on the dropdown menu, and search for Google Analytics Data API we want to enable this api, than reading the docs. Read the Api quick start from google docs, to get started with this client library. To call this report we use @google-analytics/data a client library for node js, and we call runReport method to return a customized report of our google analytics event data. // propertyId = 'YOUR-GA4-PROPERTY-ID'; // Imports the Google Analytics Data API client library. const {BetaAnalyticsDataClient} = require('@google-analytics/data'); const credentials = require(\"credentials.json\"); // Using a default constructor instructs the client to use the credentials // specified in GOOGLE_APPLICATION_CREDENTIALS environment variable. // We get the credentials by enabling the api in api quick start const analyticsDataClient = new BetaAnalyticsDataClient({ credentials }); // Runs a simple report. // propertyId and dimension are fetched from client side const [response] = await analyticsDataClient.runReport({ property: `properties/${propertyId}`, dateRanges: [ { startDate: \"2020-03-31\", endDate: \"today\", }, ], dimensions: [{ name: `${dimension}` }], metrics: [ { name: \"activeUsers\" }, { name: \"newUsers\" }, { name: \"totalUsers\" }, ], }); console.log('Report result:'); response.rows.forEach(row => { console.log(row.dimensionValues[0], row.metricValues[0]); }); } The following dimensions can be requested in reports for any property. Specify the \"API Name\" in a Dimension's name field for a column of the dimension in the report response. The following metrics can be requested in reports for any property. Specify the \"API Name\" in a Metric's name field for a column of the metric in the report response. To fetch the propertyId: - First go to your Google Analytics Dashboard - Go to Admin Section on the bottom left corner of your Google Analytics dashboard. On this page you'll see on the center the Property Settings, go to that section and copy your PROPERTY ID to our input above. - If you don't have a Google Analytics 4 property created for your site go on the Admin Page and follow up with the Setup Assistant to create this property.","title":"Google Analytics Data API"},{"location":"MetryV%20Info/","text":"MetryV Info Credentials Server Credentials Enviroment User Password Cron root Z4hK^VACa@cJbXY@z5h5g6aHzn Dev Backend root 8z%5TZF#2ZEeq5a7D$n7JG^Io9 Dev Frontend root dYIIx@fdc$8N^P&L#lk1i\\*Dy^8 Live Backend root !8iDGTv&K2Lp#^S&bwsiyXx9co Live Frontend root 3z50J^Mu2fDiZYtBP7Z#OHM@^9 Users and Passwords Enviroment User Password HTTP Authentication nehar F8oTI4aL5Aty1qoD3tgisgnf Wordpress metryv 8SWIF5e)7JUwXVgZFtWrmLPi Docker Hub Metryv Starlabs123321@ Dashboard Dev nehar@gmail.com nehari123 Dashboard metricsvitals@gmail.com MetryV!@#123. Suggestions nehar F8oTI4aL5Aty1qoD3tgisgnf Logs neharjashari `vfb'CXz?$ApX4D[96%/ Mailjet metryv@starlabspro.com M3tryV123! Email metryv@starlabspro.com B@bloki17051998! Gmail metricsvitals@gmail.com #MetryV!@#123. CloudFlare metryv@starlabspro.com T%swWPRN2Yu2 References Running Node & MongoDB with Docker Compose User Authentication Reference Dashboard UI Template Domains Wordpress DEV: https://dev.metryv.com/ Dashboard DEV: https://dev-dashboard.metryv.com/ Suggestions DEV: https://dev-suggestions-dashboard.metryv.com/ Wordpress: https://metryv.com/ Dashboard: https://dashboard.metryv.com/ Suggestions: https://suggestions-dashboard.metryv.com/ Logs: http://logs-dashboard.metryv.com/ Bookmarks Gitlab: https://gitlab.com/metryv Atlassian: https://metryv.atlassian.net/ Jira: https://metryv.atlassian.net/jira/software/c/projects/MET/boards/2 Figma: https://www.figma.com/file/JhHeTsPjpkQotjjiM3f5SS/MetryV?node-id=0%3A1 Pricing: https://docs.google.com/spreadsheets/d/1noBZmUKcUcX-8O854v-YAWbYeXbkoUEzsXq7qjUJv4A/edit?usp=sharing Documentation on psi: https://docs-performance.starlabs.dev/ - starlabs/giggity GA Property Id: 310384601 Social Media Facebook: https://www.facebook.com/metryV LinkedIn: https://www.linkedin.com/company/metryv Instagram: https://www.instagram.com/metry.v/ Twitter: https://twitter.com/metry_v Tiktok: https://www.tiktok.com/@metryv const targetElements = document.getElementsByClassName(\"password\"); for(const element of targetElements){ element.style.filter = \"blur(4px)\"; element.addEventListener(\"click\", (el) => { el.target.style.filter = \"blur(0px)\"; }) }","title":"MetryV Info"},{"location":"MetryV%20Info/#metryv-info","text":"","title":"MetryV Info"},{"location":"MetryV%20Info/#credentials","text":"","title":"Credentials"},{"location":"MetryV%20Info/#server-credentials","text":"Enviroment User Password Cron root Z4hK^VACa@cJbXY@z5h5g6aHzn Dev Backend root 8z%5TZF#2ZEeq5a7D$n7JG^Io9 Dev Frontend root dYIIx@fdc$8N^P&L#lk1i\\*Dy^8 Live Backend root !8iDGTv&K2Lp#^S&bwsiyXx9co Live Frontend root 3z50J^Mu2fDiZYtBP7Z#OHM@^9","title":"Server Credentials"},{"location":"MetryV%20Info/#users-and-passwords","text":"Enviroment User Password HTTP Authentication nehar F8oTI4aL5Aty1qoD3tgisgnf Wordpress metryv 8SWIF5e)7JUwXVgZFtWrmLPi Docker Hub Metryv Starlabs123321@ Dashboard Dev nehar@gmail.com nehari123 Dashboard metricsvitals@gmail.com MetryV!@#123. Suggestions nehar F8oTI4aL5Aty1qoD3tgisgnf Logs neharjashari `vfb'CXz?$ApX4D[96%/ Mailjet metryv@starlabspro.com M3tryV123! Email metryv@starlabspro.com B@bloki17051998! Gmail metricsvitals@gmail.com #MetryV!@#123. CloudFlare metryv@starlabspro.com T%swWPRN2Yu2","title":"Users and Passwords"},{"location":"MetryV%20Info/#references","text":"Running Node & MongoDB with Docker Compose User Authentication Reference Dashboard UI Template","title":"References"},{"location":"MetryV%20Info/#domains","text":"Wordpress DEV: https://dev.metryv.com/ Dashboard DEV: https://dev-dashboard.metryv.com/ Suggestions DEV: https://dev-suggestions-dashboard.metryv.com/ Wordpress: https://metryv.com/ Dashboard: https://dashboard.metryv.com/ Suggestions: https://suggestions-dashboard.metryv.com/ Logs: http://logs-dashboard.metryv.com/","title":"Domains"},{"location":"MetryV%20Info/#bookmarks","text":"Gitlab: https://gitlab.com/metryv Atlassian: https://metryv.atlassian.net/ Jira: https://metryv.atlassian.net/jira/software/c/projects/MET/boards/2 Figma: https://www.figma.com/file/JhHeTsPjpkQotjjiM3f5SS/MetryV?node-id=0%3A1 Pricing: https://docs.google.com/spreadsheets/d/1noBZmUKcUcX-8O854v-YAWbYeXbkoUEzsXq7qjUJv4A/edit?usp=sharing Documentation on psi: https://docs-performance.starlabs.dev/ - starlabs/giggity GA Property Id: 310384601","title":"Bookmarks"},{"location":"MetryV%20Info/#social-media","text":"Facebook: https://www.facebook.com/metryV LinkedIn: https://www.linkedin.com/company/metryv Instagram: https://www.instagram.com/metry.v/ Twitter: https://twitter.com/metry_v Tiktok: https://www.tiktok.com/@metryv const targetElements = document.getElementsByClassName(\"password\"); for(const element of targetElements){ element.style.filter = \"blur(4px)\"; element.addEventListener(\"click\", (el) => { el.target.style.filter = \"blur(0px)\"; }) }","title":"Social Media"},{"location":"On%20Release/","text":"On Release Branch Naming Convention Please use the following convention when naming a branch, so that is easier for us to track changes and for you to save versions of code. <author>_<branch-type>_<branch-name> The branch-type can be one of these: feat must be used when a branch adds a new feature to the component. fix must be used to denote branch that fix specific bugs in the component. chore identifies branch composed of only housekeeping tasks such as cleanup, merges, ... doc identifies branch representing documentation activities The branch_name can be the name of the feature, fix, etc. Commit Convention There is no globally accepted standard or a one-size-fits-all convention for git commits but when pushing to master we chose to adopt the guidelines of Conventional-Commits {:target=\"_blank\"}. When creating a PR to master branch keep in mind that the commit should follow the type description guide below, and also you have remember to select Squash and Merge option when merging to master. Type Descriptor: The type descriptor should be a noun specifying the class/category of actions the commits belong to; as recommended from the conventional-commits specification sheet: feat: must be used when a commit adds a new feature to the component. fix: must be used to denote commits that fix specific bugs in the component. chore: identifies commits composed of only housekeeping tasks such as cleanup, merges, ... doc: identifies commits representing documentation activities A quick example: fix: set correct i18n key in object edit dialog Release on live master branch frontend After every release on live front end, live server should be accessed and these commands should be run cd /opt/metryV which will go to root folder on production, then // access dashboard terminal docker exec -it dashboard bash // create a production build npm run build //after build is done type in: exit same should be applied on suggestions docker exec -it suggestions bash npm run build after a production build is created type in: exit this will create a prodcuiton build for suggestions and dashboard which will be served to the client.","title":"On Release"},{"location":"On%20Release/#on-release","text":"","title":"On Release"},{"location":"On%20Release/#branch-naming-convention","text":"Please use the following convention when naming a branch, so that is easier for us to track changes and for you to save versions of code. <author>_<branch-type>_<branch-name> The branch-type can be one of these: feat must be used when a branch adds a new feature to the component. fix must be used to denote branch that fix specific bugs in the component. chore identifies branch composed of only housekeeping tasks such as cleanup, merges, ... doc identifies branch representing documentation activities The branch_name can be the name of the feature, fix, etc.","title":"Branch Naming Convention"},{"location":"On%20Release/#commit-convention","text":"There is no globally accepted standard or a one-size-fits-all convention for git commits but when pushing to master we chose to adopt the guidelines of Conventional-Commits {:target=\"_blank\"}. When creating a PR to master branch keep in mind that the commit should follow the type description guide below, and also you have remember to select Squash and Merge option when merging to master.","title":"Commit Convention"},{"location":"On%20Release/#type-descriptor","text":"The type descriptor should be a noun specifying the class/category of actions the commits belong to; as recommended from the conventional-commits specification sheet: feat: must be used when a commit adds a new feature to the component. fix: must be used to denote commits that fix specific bugs in the component. chore: identifies commits composed of only housekeeping tasks such as cleanup, merges, ... doc: identifies commits representing documentation activities A quick example: fix: set correct i18n key in object edit dialog","title":"Type Descriptor:"},{"location":"On%20Release/#release-on-live-master-branch-frontend","text":"After every release on live front end, live server should be accessed and these commands should be run cd /opt/metryV which will go to root folder on production, then // access dashboard terminal docker exec -it dashboard bash // create a production build npm run build //after build is done type in: exit same should be applied on suggestions docker exec -it suggestions bash npm run build after a production build is created type in: exit this will create a prodcuiton build for suggestions and dashboard which will be served to the client.","title":"Release on live master branch frontend"},{"location":"Packages/","text":"Packages Redux Core (v4.1.1) The Redux core library is available as a package on NPM for use with a module bundler or in a Node application: npm install redux Along with redux we use other packages like: redux-thunk (v2.3.0) , which allows us to write functions with logic inside, that can interact with Redux's store dispatch and getState methods. redux-logger (v4.0.0) , This library logs actions in developer console, giving traceable stack of user actions. redux-devtools-extension (v2.13.9) with Redux DevTools Extension , Redux DevTools for debugging application's state changes. The extension provides power-ups for your Redux development workflow. Apart from Redux, it can be used with any other architectures which handle the state. All of these are applies as middlewares in redux store. Node-cron (v3.0.0) The node-cron module is tiny task scheduler in pure JavaScript for node.js based on GNU crontab. This module allows you to schedule task in node.js using full crontab syntax. \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 second (optional) \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 minute \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 hour \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 day of month \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500 month \u2502 \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500 day of week \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 * * * * * * cron.schedule(\"* * * * *\", asy..... Node-Mailjet (v3.3.5) The mailjet is the smtp used in metryv, currently is free tier, meaning it can deliver up to 200 emails per day, or 1600 per month. The Mailjet Email API uses your public and secret keys for authentication. MJ_APIKEY_PUBLIC 50aeacf41fc0105336a92916902f0151 MJ_APIKEY_PRIVATE 92a45433ecc48355c02b40e17837b871 Jsonwebtoken (v8.5.1) Jsonwebtoken allows us to decode, verify and generate jwt's. JWT is used in metryv to authenticate users on login or register, this package is also used in backend middlewares to authenticate api calls. Metryv uses a middleware [ validJWTNeeded ] to verify the jwt fetched from clients api call on authorization header, this token is then decoded through (\"jsonwebtoken\").verify(token,secret) function, passing the token and the same secret that was used to create that token. The contents are stored on a constant first, then on the request body. Checkout this middleware in /middlewares/auth.validation.middleware.js Socket.io (backend) - Socket.io-client (frontend) (v4.5.1) Socket.IO is a library that enables low-latency, bidirectional and event-based communication between a client and a server. It is built on top of the WebSocket protocol and provides additional guarantees like fallback to HTTP long-polling or automatic reconnection. Metryv uses socket io in chat_server microservices Ping ( CheckHost ) Check-Host is a modern online tool for website monitoring and checking availability of hosts, DNS records, IP addresses. It supports the latest technologies such as localized domain names (both punycode and original formats), hostname IPv6 records (also known as AAAA record). Ping allows you to test the reachability of a host and to measure the round-trip time for messages sent from the originating host to a destination computer. First we check the available hosts by making the api call on our backend server, on this url https://check-host.net/nodes/hosts . The availble hosts are then parsed to check the ping of given url from each given region(host) Then we check the ping of given url by the client by runing command on bash curl -H \"Accept: application/json\" \\ 'https://check-host.net/check-ping?host=<site_url><&node=....> After checking the ping we are given a request_id to check the results, with that request_id we make an api call on this url https://check-host.net/check-result/$<request_id> to see all the results. When releasing on production make sure to install curl on server const targetElements = document.getElementsByClassName(\"password\"); for(const element of targetElements){ element.style.filter = \"blur(4px)\"; element.addEventListener(\"click\", (el) => { el.target.style.filter = \"blur(0px)\"; }) }","title":"Packages"},{"location":"Packages/#packages","text":"","title":"Packages"},{"location":"Packages/#redux-core-v411","text":"The Redux core library is available as a package on NPM for use with a module bundler or in a Node application: npm install redux Along with redux we use other packages like: redux-thunk (v2.3.0) , which allows us to write functions with logic inside, that can interact with Redux's store dispatch and getState methods. redux-logger (v4.0.0) , This library logs actions in developer console, giving traceable stack of user actions. redux-devtools-extension (v2.13.9) with Redux DevTools Extension , Redux DevTools for debugging application's state changes. The extension provides power-ups for your Redux development workflow. Apart from Redux, it can be used with any other architectures which handle the state. All of these are applies as middlewares in redux store.","title":"Redux Core (v4.1.1)"},{"location":"Packages/#node-cron-v300","text":"The node-cron module is tiny task scheduler in pure JavaScript for node.js based on GNU crontab. This module allows you to schedule task in node.js using full crontab syntax. \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 second (optional) \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 minute \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 hour \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 day of month \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500 month \u2502 \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500 day of week \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 * * * * * * cron.schedule(\"* * * * *\", asy.....","title":"Node-cron (v3.0.0)"},{"location":"Packages/#node-mailjet-v335","text":"The mailjet is the smtp used in metryv, currently is free tier, meaning it can deliver up to 200 emails per day, or 1600 per month. The Mailjet Email API uses your public and secret keys for authentication. MJ_APIKEY_PUBLIC 50aeacf41fc0105336a92916902f0151 MJ_APIKEY_PRIVATE 92a45433ecc48355c02b40e17837b871","title":"Node-Mailjet (v3.3.5)"},{"location":"Packages/#jsonwebtoken-v851","text":"Jsonwebtoken allows us to decode, verify and generate jwt's. JWT is used in metryv to authenticate users on login or register, this package is also used in backend middlewares to authenticate api calls. Metryv uses a middleware [ validJWTNeeded ] to verify the jwt fetched from clients api call on authorization header, this token is then decoded through (\"jsonwebtoken\").verify(token,secret) function, passing the token and the same secret that was used to create that token. The contents are stored on a constant first, then on the request body. Checkout this middleware in /middlewares/auth.validation.middleware.js","title":"Jsonwebtoken (v8.5.1)"},{"location":"Packages/#socketio-backend-socketio-client-frontend-v451","text":"Socket.IO is a library that enables low-latency, bidirectional and event-based communication between a client and a server. It is built on top of the WebSocket protocol and provides additional guarantees like fallback to HTTP long-polling or automatic reconnection. Metryv uses socket io in chat_server microservices","title":"Socket.io (backend) - Socket.io-client (frontend) (v4.5.1)"},{"location":"Packages/#ping-checkhost","text":"Check-Host is a modern online tool for website monitoring and checking availability of hosts, DNS records, IP addresses. It supports the latest technologies such as localized domain names (both punycode and original formats), hostname IPv6 records (also known as AAAA record). Ping allows you to test the reachability of a host and to measure the round-trip time for messages sent from the originating host to a destination computer. First we check the available hosts by making the api call on our backend server, on this url https://check-host.net/nodes/hosts . The availble hosts are then parsed to check the ping of given url from each given region(host) Then we check the ping of given url by the client by runing command on bash curl -H \"Accept: application/json\" \\ 'https://check-host.net/check-ping?host=<site_url><&node=....> After checking the ping we are given a request_id to check the results, with that request_id we make an api call on this url https://check-host.net/check-result/$<request_id> to see all the results. When releasing on production make sure to install curl on server const targetElements = document.getElementsByClassName(\"password\"); for(const element of targetElements){ element.style.filter = \"blur(4px)\"; element.addEventListener(\"click\", (el) => { el.target.style.filter = \"blur(0px)\"; }) }","title":"Ping (CheckHost)"},{"location":"Paysera/","text":"Paysera ( docs ) The Checkout API (Payment Gateway API) allows for the collection of online payments with many payment methods. Use one of our methods and the checkout processes will be performed automatically. The Checkout API works by sending a payment request to Paysera\u2019s servers with payment parameters. After the integration, your website\u2019s customer will have the opportunity to choose from all of your desired payment methods. Once the payment is made, the customer is redirected to the \u2018thank you\u2019 page provided by you. Once the payment is confirmed, we send the relevant information back to your website. Paysera is implemented in metryv with an integrtation library: webtopay . To see how we implemented paysera in metryv with this library check out this documantation in paysera checkout . We create an url on frontend with metryv.com/payment domain and on there we concatenate userid, subscription plan and annual value https://metryv.com/payment/redirect.php?name=<subscription plan>&user=<userId>&annual=<true|false> This will execute redirect.php file on payments, then there two api call will take place which will return subscription plans price annually or monthly and users full name. // plan price $plan = json_decode(CallAPI(\"GET\", \"https://backend-dashboard.metryv.com/api/plan/single\", array(\"name\" => $subscription, \"user\" => $user))); // users data $user_fullname = json_decode(CallAPI(\"GET\", \"https://backend-dashboard.metryv.com/api/usersname\", array(\"userId\" => $user))); redirectToPayment method of WebToPay library will redirect us to payment process on paysera. After that process we are redirected to accept.php , where an api call to updated user's data on our backend will take place //update users data on our database $apiCall = CallAPI(\"GET\", \"https://backend-dashboard.metryv.com/api/plan/callback\", array(\"data\" => $data, \"ss1\" => $ss1, \"ss2\" => $ss2)); Callback parameters projectid Unique project number, fetched from starlabs paysera account accepturl Full address (URL), to which the client is directed after a successful payment. When a user is directed in accept.php, users data are updated cancelurl Full address (URL), to which the client is directed after he clicks the link to return to the shop. callbackurl Full address (URL), to which a seller will get information about performed payment. Script must return text \"OK\". Only then our system will register, that information about the payment has been received. If there is no answer \"OK\", the message will be sent 4 times (when we get it, after an hour, after three hours and after 24 hours). user User fetched from our database plan Subscription plan fetched from database test If you want to try test payments locally use [test => 1]. Make sure you are on test branch, and all url's on payments project are on localhost. On backend update plan.controller.js file on callback function replace the website endpoint to websiteEndpointLocal. On frontend update the checkout.js file with the localhost domain on anchor tag.","title":"Paysera"},{"location":"Paysera/#paysera-docs","text":"The Checkout API (Payment Gateway API) allows for the collection of online payments with many payment methods. Use one of our methods and the checkout processes will be performed automatically. The Checkout API works by sending a payment request to Paysera\u2019s servers with payment parameters. After the integration, your website\u2019s customer will have the opportunity to choose from all of your desired payment methods. Once the payment is made, the customer is redirected to the \u2018thank you\u2019 page provided by you. Once the payment is confirmed, we send the relevant information back to your website. Paysera is implemented in metryv with an integrtation library: webtopay . To see how we implemented paysera in metryv with this library check out this documantation in paysera checkout . We create an url on frontend with metryv.com/payment domain and on there we concatenate userid, subscription plan and annual value https://metryv.com/payment/redirect.php?name=<subscription plan>&user=<userId>&annual=<true|false> This will execute redirect.php file on payments, then there two api call will take place which will return subscription plans price annually or monthly and users full name. // plan price $plan = json_decode(CallAPI(\"GET\", \"https://backend-dashboard.metryv.com/api/plan/single\", array(\"name\" => $subscription, \"user\" => $user))); // users data $user_fullname = json_decode(CallAPI(\"GET\", \"https://backend-dashboard.metryv.com/api/usersname\", array(\"userId\" => $user))); redirectToPayment method of WebToPay library will redirect us to payment process on paysera. After that process we are redirected to accept.php , where an api call to updated user's data on our backend will take place //update users data on our database $apiCall = CallAPI(\"GET\", \"https://backend-dashboard.metryv.com/api/plan/callback\", array(\"data\" => $data, \"ss1\" => $ss1, \"ss2\" => $ss2));","title":"Paysera (docs)"},{"location":"Paysera/#callback-parameters","text":"projectid Unique project number, fetched from starlabs paysera account accepturl Full address (URL), to which the client is directed after a successful payment. When a user is directed in accept.php, users data are updated cancelurl Full address (URL), to which the client is directed after he clicks the link to return to the shop. callbackurl Full address (URL), to which a seller will get information about performed payment. Script must return text \"OK\". Only then our system will register, that information about the payment has been received. If there is no answer \"OK\", the message will be sent 4 times (when we get it, after an hour, after three hours and after 24 hours). user User fetched from our database plan Subscription plan fetched from database test If you want to try test payments locally use [test => 1]. Make sure you are on test branch, and all url's on payments project are on localhost. On backend update plan.controller.js file on callback function replace the website endpoint to websiteEndpointLocal. On frontend update the checkout.js file with the localhost domain on anchor tag.","title":"Callback parameters"},{"location":"Running%20the%20project/","text":"Running the project Npm MetryV Back There are four microservices and you should run them seperatly with npm. First you'll need to install all npm install packages on all four services by running npm install than you'll start the servers by running npm start that will run the command declared on package.json for each microservice Local \"start\": \"nodemon index.js\" Development \"start:development\": \"NODE_ENV=development node --max-old-space-size=4096 index.js\" Production \"start:production\": \"NODE_ENV=production node --max-old-space-size=4096 index.js\" Crons \"start:crons\": \"NODE_ENV=crons node --max-old-space-size=4096 --no-warnings index.js\" nodemon: is a tool that helps develop Node.js based applications by automatically restarting the node application when file changes in the directory are detected. NODE_ENV: will declare the node_env variable on .env file and will start the app in that environment --max-old-space-size: By default, the memory limit in Node. js is 512 MB. To increase this amount, you need to set the memory limit argument \u2014-max-old-space-size . It will help avoid a memory limit issue. --no-warnings: disables warnings in node js Ports and env variables are specified on the table below for each enviroment Service Local Development Production API http://localhost:3001/api https://backend-dev.metryv.com/api https://backend-dashboard.metryv.com/api PSI http://localhost:3002/psi https://backend-dev.metryv.com/psi https://backend-dashboard.metryv.com/psi CHAT SERVER http://localhost:3004/chat https://backend-dev.metryv.com/chat https://backend-dashboard.metryv.com/chat PING http://localhost:3005/ping https://backend-dev.metryv.com/ping https://backend-dashboard.metryv.com/ping MetryV Front There are two services and you should run them seperatly with npm. First you will need to npm install all npm packages each service by running npm install than you'll start dashboard and suggestions by running npm start that will run the command decalred on package.json for suggestions and dashboard Local \"start\": \"env-cmd -f .env.local react-scripts start\" Development \"start:development\": \"env-cmd -f .env.development react-scripts start\" Production \"start:production\": \"env-cmd -f .env.production react-scripts start\" env-cmd -f .env.local|development|production: A simple node program for executing commands using an environment from an env file. -f determines which .env file to process on that enviroment Ports and env variables are specified on the table below for each container Service Local Development Production DASHBOARD http://localhost:3000/ https://dev-dashboard.metryv.com/ https://dashboard.metryv.com/ SUGGESTIONS http://localhost:3003/ https://dev-suggestions.metryv.com/ https://suggestions.metryv.com/ Xamp Run xamp and click on start all to be able to use metryv payments locally or metryv landing page Service Local Development Production PAYMENTS http://localhost/payment/ https://metryv.com/payment/ METRYV http://localhost/metryv/ https://dev.metryv.com/ https://metryv.com/","title":"Running the project"},{"location":"Running%20the%20project/#running-the-project","text":"","title":"Running the project"},{"location":"Running%20the%20project/#npm","text":"","title":"Npm"},{"location":"Running%20the%20project/#metryv-back","text":"There are four microservices and you should run them seperatly with npm. First you'll need to install all npm install packages on all four services by running npm install than you'll start the servers by running npm start that will run the command declared on package.json for each microservice Local \"start\": \"nodemon index.js\" Development \"start:development\": \"NODE_ENV=development node --max-old-space-size=4096 index.js\" Production \"start:production\": \"NODE_ENV=production node --max-old-space-size=4096 index.js\" Crons \"start:crons\": \"NODE_ENV=crons node --max-old-space-size=4096 --no-warnings index.js\" nodemon: is a tool that helps develop Node.js based applications by automatically restarting the node application when file changes in the directory are detected. NODE_ENV: will declare the node_env variable on .env file and will start the app in that environment --max-old-space-size: By default, the memory limit in Node. js is 512 MB. To increase this amount, you need to set the memory limit argument \u2014-max-old-space-size . It will help avoid a memory limit issue. --no-warnings: disables warnings in node js Ports and env variables are specified on the table below for each enviroment Service Local Development Production API http://localhost:3001/api https://backend-dev.metryv.com/api https://backend-dashboard.metryv.com/api PSI http://localhost:3002/psi https://backend-dev.metryv.com/psi https://backend-dashboard.metryv.com/psi CHAT SERVER http://localhost:3004/chat https://backend-dev.metryv.com/chat https://backend-dashboard.metryv.com/chat PING http://localhost:3005/ping https://backend-dev.metryv.com/ping https://backend-dashboard.metryv.com/ping","title":"MetryV Back"},{"location":"Running%20the%20project/#metryv-front","text":"There are two services and you should run them seperatly with npm. First you will need to npm install all npm packages each service by running npm install than you'll start dashboard and suggestions by running npm start that will run the command decalred on package.json for suggestions and dashboard Local \"start\": \"env-cmd -f .env.local react-scripts start\" Development \"start:development\": \"env-cmd -f .env.development react-scripts start\" Production \"start:production\": \"env-cmd -f .env.production react-scripts start\" env-cmd -f .env.local|development|production: A simple node program for executing commands using an environment from an env file. -f determines which .env file to process on that enviroment Ports and env variables are specified on the table below for each container Service Local Development Production DASHBOARD http://localhost:3000/ https://dev-dashboard.metryv.com/ https://dashboard.metryv.com/ SUGGESTIONS http://localhost:3003/ https://dev-suggestions.metryv.com/ https://suggestions.metryv.com/","title":"MetryV Front"},{"location":"Running%20the%20project/#xamp","text":"Run xamp and click on start all to be able to use metryv payments locally or metryv landing page Service Local Development Production PAYMENTS http://localhost/payment/ https://metryv.com/payment/ METRYV http://localhost/metryv/ https://dev.metryv.com/ https://metryv.com/","title":"Xamp"},{"location":"Setting%20up%20the%20project/","text":"Setting up the project Tech Stack The technology stack used in metryv is mostly MERN Stack (MongoDB, Express.js, React.js, Node.js). MongoDB is used as a database where all the data is stored, it consists of 9 collections. We use seperate databases for production and development enviroments. Node.js a javascript runtime enviroment and Express.js framework are used in the backend part of this application with microservice architecture. React.js 17.0.2 a javascript library is used on frontend togethere with a template Shards Dashboard Lite React and React Redux Core a state managment tool. On payments metryv uses a library by paysera: webtopay created with PHP , and the metryv landing page metryv.com is created with wordpress/PHP . Docker is used to create containers along with docker-compose to build and start containers Node js & npm First thing you will need to do is installing node.js on your machine [ node 16.13.0 or later LTS versions], along with installing nodejs you will also need npm package manger tool to install the project dependecies Xampp and Worpress Install Xampp version 8.0.18-0 and Wrodpress to run landing page metryv.com and payments service on backend After git cloning payments and landing page, save their folders on /opt/lampp/htdocs and rename them to payment and metryv . Gitlab Repos There are four git repos of metryv MetryV Back git clone https://gitlab.com/metryv/metryv-back.git MetryV Front git clone https://gitlab.com/metryv/metryv-front.git MetryV Payments git clone https://gitlab.com/metryv/metryv-payments.git MetryV Wordpress git clone https://gitlab.com/metryv/metryv-wordpress.git Enviroments Besides local enviroment on frontend, backend, payments and metryv landing page there are these enviroments included ENV 1 ENV 2 ENV 3 ENV 4 Backend Local Development Production Crons Frontend Local Development Production Payments Local Production Metryv - Landing Page Local Development Production EsLint & Prettier ESLint statically analyzes your code to quickly find problems. It is built into most text editors and you can run ESLint as part of your continuous integration pipeline. Backend setup: ESLint { \"root\": true, \"parserOptions\": { \"ecmaVersion\": 12, \"sourceType\": \"module\" }, \"extends\": [\"eslint:recommended\", \"prettier\"], \"env\": { \"es2021\": true, \"node\": true } } Specifying Parser Options: parserOptions ESLint allows you to specify the JavaScript language options you want to support. We use ECMAScript 12 syntax and source type module. Extends ESLint Recommended and Prettier: eslint:recommended This means we use the eslint recommended rules, check them out here . prettier This lets you use your favorite shareable config without letting its stylistic choices get in the way when using Prettier. Note that this config only turns rules off, so it only makes sense using it together with some other config. Prettier { \"trailingComma\": \"es5\", \"tabWidth\": 4, \"semi\": true } Trailing Commas: Print trailing commas wherever possible in multi-line comma-separated syntactic structures. (A single-line array, for example, never gets trailing commas.). trailingComma: es5 - Trailing commas where valid in ES5 (objects, arrays, etc.). No trailing commas in type parameters in TypeScript. Tab Width: Specify the number of spaces per indentation-level. tabWidth: 4 - sets the tab width to 4 spaces Semicolons: Print semicolons at the ends of statements. semi: true , adds a semicolon at the end of every statement. Frontend setup We use a npm package esling-plugin-react \"extends\": [ \"eslint:recommended\", \"plugin:react/recommended\" ] rules: { \"prettier/prettier\": [ \"error\", { endOfLine: \"auto\", }, ], \"react/prop-types\": 0, \"linebreak-style\": 0, \"arrow-body-style\": \"off\", \"prefer-arrow-callback\": \"off\", }, You are ready to use Prettier and ESLint in your project without worrying about any conflicts. ESLint knows about all your Prettier rules by integrating all the rules that are enforced by it and removing all the rules that could conflict with it. Now there shouldn't be anything in your way for an improved code style and structure. If you need to exclude folders/files from your ESLint rules, you can add these in an .eslintignore file. Any declared unused variable, function, array etc, any not formated code will throw an error and the page will not compile. If we want to disable these rules we use /* eslint-disable */ at the top of the file for that whole file, or /* eslint-disable-next-line */ for the next line.","title":"Setting up the project"},{"location":"Setting%20up%20the%20project/#setting-up-the-project","text":"","title":"Setting up the project"},{"location":"Setting%20up%20the%20project/#tech-stack","text":"The technology stack used in metryv is mostly MERN Stack (MongoDB, Express.js, React.js, Node.js). MongoDB is used as a database where all the data is stored, it consists of 9 collections. We use seperate databases for production and development enviroments. Node.js a javascript runtime enviroment and Express.js framework are used in the backend part of this application with microservice architecture. React.js 17.0.2 a javascript library is used on frontend togethere with a template Shards Dashboard Lite React and React Redux Core a state managment tool. On payments metryv uses a library by paysera: webtopay created with PHP , and the metryv landing page metryv.com is created with wordpress/PHP . Docker is used to create containers along with docker-compose to build and start containers","title":"Tech Stack"},{"location":"Setting%20up%20the%20project/#node-js-npm","text":"First thing you will need to do is installing node.js on your machine [ node 16.13.0 or later LTS versions], along with installing nodejs you will also need npm package manger tool to install the project dependecies","title":"Node js &amp; npm"},{"location":"Setting%20up%20the%20project/#xampp-and-worpress","text":"Install Xampp version 8.0.18-0 and Wrodpress to run landing page metryv.com and payments service on backend After git cloning payments and landing page, save their folders on /opt/lampp/htdocs and rename them to payment and metryv .","title":"Xampp and Worpress"},{"location":"Setting%20up%20the%20project/#gitlab-repos","text":"There are four git repos of metryv MetryV Back git clone https://gitlab.com/metryv/metryv-back.git MetryV Front git clone https://gitlab.com/metryv/metryv-front.git MetryV Payments git clone https://gitlab.com/metryv/metryv-payments.git MetryV Wordpress git clone https://gitlab.com/metryv/metryv-wordpress.git","title":"Gitlab Repos"},{"location":"Setting%20up%20the%20project/#enviroments","text":"Besides local enviroment on frontend, backend, payments and metryv landing page there are these enviroments included ENV 1 ENV 2 ENV 3 ENV 4 Backend Local Development Production Crons Frontend Local Development Production Payments Local Production Metryv - Landing Page Local Development Production","title":"Enviroments"},{"location":"Setting%20up%20the%20project/#eslint-prettier","text":"ESLint statically analyzes your code to quickly find problems. It is built into most text editors and you can run ESLint as part of your continuous integration pipeline.","title":"EsLint &amp; Prettier"},{"location":"Setting%20up%20the%20project/#backend-setup","text":"","title":"Backend setup:"},{"location":"Setting%20up%20the%20project/#eslint","text":"{ \"root\": true, \"parserOptions\": { \"ecmaVersion\": 12, \"sourceType\": \"module\" }, \"extends\": [\"eslint:recommended\", \"prettier\"], \"env\": { \"es2021\": true, \"node\": true } } Specifying Parser Options: parserOptions ESLint allows you to specify the JavaScript language options you want to support. We use ECMAScript 12 syntax and source type module. Extends ESLint Recommended and Prettier: eslint:recommended This means we use the eslint recommended rules, check them out here . prettier This lets you use your favorite shareable config without letting its stylistic choices get in the way when using Prettier. Note that this config only turns rules off, so it only makes sense using it together with some other config.","title":"ESLint"},{"location":"Setting%20up%20the%20project/#prettier","text":"{ \"trailingComma\": \"es5\", \"tabWidth\": 4, \"semi\": true } Trailing Commas: Print trailing commas wherever possible in multi-line comma-separated syntactic structures. (A single-line array, for example, never gets trailing commas.). trailingComma: es5 - Trailing commas where valid in ES5 (objects, arrays, etc.). No trailing commas in type parameters in TypeScript. Tab Width: Specify the number of spaces per indentation-level. tabWidth: 4 - sets the tab width to 4 spaces Semicolons: Print semicolons at the ends of statements. semi: true , adds a semicolon at the end of every statement.","title":"Prettier"},{"location":"Setting%20up%20the%20project/#frontend-setup","text":"We use a npm package esling-plugin-react \"extends\": [ \"eslint:recommended\", \"plugin:react/recommended\" ] rules: { \"prettier/prettier\": [ \"error\", { endOfLine: \"auto\", }, ], \"react/prop-types\": 0, \"linebreak-style\": 0, \"arrow-body-style\": \"off\", \"prefer-arrow-callback\": \"off\", }, You are ready to use Prettier and ESLint in your project without worrying about any conflicts. ESLint knows about all your Prettier rules by integrating all the rules that are enforced by it and removing all the rules that could conflict with it. Now there shouldn't be anything in your way for an improved code style and structure. If you need to exclude folders/files from your ESLint rules, you can add these in an .eslintignore file. Any declared unused variable, function, array etc, any not formated code will throw an error and the page will not compile. If we want to disable these rules we use /* eslint-disable */ at the top of the file for that whole file, or /* eslint-disable-next-line */ for the next line.","title":"Frontend setup"}]}